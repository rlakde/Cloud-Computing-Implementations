 spark-submit --class SparkSort --master yarn --deploy-mode client --driver-memory 1g --executor-memory 1g --executor-cores 1 --num-executors 1 SparkSort.jar /input/data-15GB /user/rlakde/output-spark
2019-04-30 09:06:04 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2019-04-30 09:06:09 INFO  SparkContext:54 - Running Spark version 2.3.0
2019-04-30 09:06:09 INFO  SparkContext:54 - Submitted application: Spark Sort
2019-04-30 09:06:09 INFO  SecurityManager:54 - Changing view acls to: rlakde
2019-04-30 09:06:09 INFO  SecurityManager:54 - Changing modify acls to: rlakde
2019-04-30 09:06:09 INFO  SecurityManager:54 - Changing view acls groups to:
2019-04-30 09:06:09 INFO  SecurityManager:54 - Changing modify acls groups to:
2019-04-30 09:06:09 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(rlakde); groups with view permissions: Set(); users  with modify permissions: Set(rlakde); groups with modify permissions: Set()
2019-04-30 09:06:09 INFO  Utils:54 - Successfully started service 'sparkDriver' on port 40459.
2019-04-30 09:06:09 INFO  SparkEnv:54 - Registering MapOutputTracker
2019-04-30 09:06:09 INFO  SparkEnv:54 - Registering BlockManagerMaster
2019-04-30 09:06:09 INFO  BlockManagerMasterEndpoint:54 - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2019-04-30 09:06:09 INFO  BlockManagerMasterEndpoint:54 - BlockManagerMasterEndpoint up
2019-04-30 09:06:09 INFO  DiskBlockManager:54 - Created local directory at /tmp/blockmgr-cbc9f485-b306-473a-b422-f23721309aa1
2019-04-30 09:06:09 INFO  MemoryStore:54 - MemoryStore started with capacity 366.3 MB
2019-04-30 09:06:09 INFO  SparkEnv:54 - Registering OutputCommitCoordinator
2019-04-30 09:06:09 INFO  log:192 - Logging initialized @2431ms
2019-04-30 09:06:06 INFO  Server:346 - jetty-9.3.z-SNAPSHOT
2019-04-30 09:06:06 INFO  Server:414 - Started @2539ms
2019-04-30 09:06:06 INFO  AbstractConnector:278 - Started ServerConnector@c074c0c{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2019-04-30 09:06:06 INFO  Utils:54 - Successfully started service 'SparkUI' on port 4040.
2019-04-30 09:06:06 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3f2049b6{/jobs,null,AVAILABLE,@Spark}
2019-04-30 09:06:06 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6b85300e{/jobs/json,null,AVAILABLE,@Spark}
2019-04-30 09:06:06 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3aaf4f07{/jobs/job,null,AVAILABLE,@Spark}
2019-04-30 09:06:06 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@18e8473e{/jobs/job/json,null,AVAILABLE,@Spark}
2019-04-30 09:06:06 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5a2f016d{/stages,null,AVAILABLE,@Spark}
2019-04-30 09:06:06 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1a38ba58{/stages/json,null,AVAILABLE,@Spark}
2019-04-30 09:06:06 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3ad394e6{/stages/stage,null,AVAILABLE,@Spark}
2019-04-30 09:06:06 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1deb2c43{/stages/stage/json,null,AVAILABLE,@Spark}
2019-04-30 09:06:06 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3bb9efbc{/stages/pool,null,AVAILABLE,@Spark}
2019-04-30 09:06:06 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1cefc4b3{/stages/pool/json,null,AVAILABLE,@Spark}
2019-04-30 09:06:06 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2b27cc70{/storage,null,AVAILABLE,@Spark}
2019-04-30 09:06:06 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6f6a7463{/storage/json,null,AVAILABLE,@Spark}
2019-04-30 09:06:06 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1bdaa23d{/storage/rdd,null,AVAILABLE,@Spark}
2019-04-30 09:06:06 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@79f227a9{/storage/rdd/json,null,AVAILABLE,@Spark}
2019-04-30 09:06:06 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6ca320ab{/environment,null,AVAILABLE,@Spark}
2019-04-30 09:06:06 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@50d68830{/environment/json,null,AVAILABLE,@Spark}
2019-04-30 09:06:06 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1e53135d{/executors,null,AVAILABLE,@Spark}
2019-04-30 09:06:06 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7674a091{/executors/json,null,AVAILABLE,@Spark}
2019-04-30 09:06:06 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3a7704c{/executors/threadDump,null,AVAILABLE,@Spark}
2019-04-30 09:06:06 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6754ef00{/executors/threadDump/json,null,AVAILABLE,@Spark}
2019-04-30 09:06:06 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@619bd14c{/static,null,AVAILABLE,@Spark}
2019-04-30 09:06:06 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@106faf11{/,null,AVAILABLE,@Spark}
2019-04-30 09:06:06 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@70f43b45{/api,null,AVAILABLE,@Spark}
2019-04-30 09:06:06 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2c282004{/jobs/job/kill,null,AVAILABLE,@Spark}
2019-04-30 09:06:06 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@22ee2d0{/stages/stage/kill,null,AVAILABLE,@Spark}
2019-04-30 09:06:06 INFO  SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://hadoop-b:4040
2019-04-30 09:06:06 INFO  SparkContext:54 - Added JAR file:/exports/home/rlakde/cs553-pa2b/SparkSort.jar at spark://hadoop-b:40459/jars/SparkSort.jar with timestamp 1524978366201
2019-04-30 09:06:07 INFO  RMProxy:98 - Connecting to ResourceManager at hadoop-b/192.168.2.61:8032
2019-04-30 09:06:07 INFO  Client:54 - Requesting a new application from cluster with 4 NodeManagers
2019-04-30 09:06:07 INFO  Client:54 - Verifying our application has not requested more than the maximum memory capability of the cluster (8192 MB per container)
2019-04-30 09:06:07 INFO  Client:54 - Will allocate AM container, with 896 MB memory including 384 MB overhead
2019-04-30 09:06:07 INFO  Client:54 - Setting up container launch context for our AM
2019-04-30 09:06:07 INFO  Client:54 - Setting up the launch environment for our AM container
2019-04-30 09:06:07 INFO  Client:54 - Preparing resources for our AM container
2019-04-30 09:06:09 WARN  Client:66 - Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME.
2019-04-30 09:06:12 INFO  Client:54 - Uploading resource file:/tmp/spark-889cbdb1-009e-472e-a47f-9f3390c00dd2/__spark_libs__4445709662036982579.zip -> hdfs://hadoop-b:9000/user/rlakde/.sparkStaging/application_1524858295679_0143/__spark_libs__4445709662036982579.zip
2019-04-30 09:06:14 INFO  Client:54 - Uploading resource file:/tmp/spark-889cbdb1-009e-472e-a47f-9f3390c00dd2/__spark_conf__1638016934427513326.zip -> hdfs://hadoop-b:9000/user/rlakde/.sparkStaging/application_1524858295679_0143/__spark_conf__.zip
2019-04-30 09:06:14 INFO  SecurityManager:54 - Changing view acls to: rlakde
2019-04-30 09:06:14 INFO  SecurityManager:54 - Changing modify acls to: rlakde
2019-04-30 09:06:14 INFO  SecurityManager:54 - Changing view acls groups to:
2019-04-30 09:06:14 INFO  SecurityManager:54 - Changing modify acls groups to:
2019-04-30 09:06:14 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(rlakde); groups with view permissions: Set(); users  with modify permissions: Set(rlakde); groups with modify permissions: Set()
2019-04-30 09:06:14 INFO  Client:54 - Submitting application application_1524858295679_0143 to ResourceManager
2019-04-30 09:06:14 INFO  YarnClientImpl:273 - Submitted application application_1524858295679_0143
2019-04-30 09:06:14 INFO  SchedulerExtensionServices:54 - Starting Yarn extension services with app application_1524858295679_0143 and attemptId None
2019-04-30 09:06:15 INFO  Client:54 - Application report for application_1524858295679_0143 (state: ACCEPTED)
2019-04-30 09:06:15 INFO  Client:54 -
	 client token: N/A
	 diagnostics: AM container is launched, waiting for AM container to Register with RM
	 ApplicationMaster host: N/A
	 ApplicationMaster RPC port: -1
	 queue: default
	 start time: 1524978374460
	 final status: UNDEFINED
	 tracking URL: http://hadoop-b:8088/proxy/application_1524858295679_0143/
	 user: rlakde
2019-04-30 09:06:16 INFO  Client:54 - Application report for application_1524858295679_0143 (state: ACCEPTED)
2019-04-30 09:06:17 INFO  Client:54 - Application report for application_1524858295679_0143 (state: ACCEPTED)
2019-04-30 09:06:18 INFO  Client:54 - Application report for application_1524858295679_0143 (state: ACCEPTED)
2019-04-30 09:06:19 INFO  Client:54 - Application report for application_1524858295679_0143 (state: ACCEPTED)
2019-04-30 09:06:20 INFO  Client:54 - Application report for application_1524858295679_0143 (state: ACCEPTED)
2019-04-30 09:06:21 INFO  Client:54 - Application report for application_1524858295679_0143 (state: ACCEPTED)
2019-04-30 09:06:22 INFO  Client:54 - Application report for application_1524858295679_0143 (state: ACCEPTED)
2019-04-30 09:06:23 INFO  Client:54 - Application report for application_1524858295679_0143 (state: ACCEPTED)
2019-04-30 09:06:24 INFO  Client:54 - Application report for application_1524858295679_0143 (state: ACCEPTED)
2019-04-30 09:06:25 INFO  Client:54 - Application report for application_1524858295679_0143 (state: ACCEPTED)
2019-04-30 09:06:26 INFO  Client:54 - Application report for application_1524858295679_0143 (state: ACCEPTED)
2019-04-30 09:06:27 INFO  YarnClientSchedulerBackend:54 - Add WebUI Filter. org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter, Map(PROXY_HOSTS -> hadoop-b, PROXY_URI_BASES -> http://hadoop-b:8088/proxy/application_1524858295679_0143), /proxy/application_1524858295679_0143
2019-04-30 09:06:27 INFO  JettyUtils:54 - Adding filter: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
2019-04-30 09:06:27 INFO  YarnSchedulerBackend$YarnSchedulerEndpoint:54 - ApplicationMaster registered as NettyRpcEndpointRef(spark-client://YarnAM)
2019-04-30 09:06:27 INFO  Client:54 - Application report for application_1524858295679_0143 (state: RUNNING)
2019-04-30 09:06:27 INFO  Client:54 -
	 client token: N/A
	 diagnostics: N/A
	 ApplicationMaster host: 192.168.2.35
	 ApplicationMaster RPC port: 0
	 queue: default
	 start time: 1524978374460
	 final status: UNDEFINED
	 tracking URL: http://hadoop-b:8088/proxy/application_1524858295679_0143/
	 user: rlakde
2019-04-30 09:06:27 INFO  YarnClientSchedulerBackend:54 - Application application_1524858295679_0143 has started running.
2019-04-30 09:06:27 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 46638.
2019-04-30 09:06:27 INFO  NettyBlockTransferService:54 - Server created on hadoop-b:46638
2019-04-30 09:06:27 INFO  BlockManager:54 - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2019-04-30 09:06:27 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, hadoop-b, 46638, None)
2019-04-30 09:06:27 INFO  BlockManagerMasterEndpoint:54 - Registering block manager hadoop-b:46638 with 366.3 MB RAM, BlockManagerId(driver, hadoop-b, 46638, None)
2019-04-30 09:06:27 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, hadoop-b, 46638, None)
2019-04-30 09:06:27 INFO  BlockManager:54 - Initialized BlockManager: BlockManagerId(driver, hadoop-b, 46638, None)
2019-04-30 09:06:27 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@448c92fc{/metrics/json,null,AVAILABLE,@Spark}
2019-04-30 09:06:33 INFO  YarnSchedulerBackend$YarnDriverEndpoint:54 - Registered executor NettyRpcEndpointRef(spark-client://Executor) (192.168.2.35:47944) with ID 1
2019-04-30 09:06:33 INFO  YarnClientSchedulerBackend:54 - SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.8
2019-04-30 09:06:34 INFO  BlockManagerMasterEndpoint:54 - Registering block manager hadoop-b-2:38142 with 366.3 MB RAM, BlockManagerId(1, hadoop-b-2, 38142, None)
2019-04-30 09:06:34 INFO  MemoryStore:54 - Block broadcast_0 stored as values in memory (estimated size 240.9 KB, free 366.1 MB)
2019-04-30 09:06:34 INFO  MemoryStore:54 - Block broadcast_0_piece0 stored as bytes in memory (estimated size 23.2 KB, free 366.0 MB)
2019-04-30 09:06:34 INFO  BlockManagerInfo:54 - Added broadcast_0_piece0 in memory on hadoop-b:46638 (size: 23.2 KB, free: 366.3 MB)
2019-04-30 09:06:34 INFO  SparkContext:54 - Created broadcast 0 from textFile at SparkSort.java:13